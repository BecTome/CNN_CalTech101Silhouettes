{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAME Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "\n",
    "RAW_DATA_PATH = 'input/data/raw'\n",
    "\n",
    "MINITRAIN_PATH = 'input/data/train/'\n",
    "MINIVAL_PATH = 'input/data/val/'\n",
    "MINITEST_PATH = 'input/data/test/'\n",
    "\n",
    "META_PATH = 'input/metadata/'\n",
    "IMG_SIZE = 28\n",
    "N_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a toy dataset much smaller than the real one. This can be pretty good to configure the whole load-train-predict pipeline before facing a much bigger problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4100, 784) (4100, 1)\n",
      "(2264, 784) (2264, 1)\n",
      "(2307, 784) (2307, 1)\n",
      "Train: 47.28% Val: 26.11% Test: 26.61%\n",
      "['Airplanes Side 2', 'Faces 2', 'Faces 3', 'Leopards', 'Motorbikes 16', 'accordion', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car side', 'ceiling fan', 'cellphone', 'chair', 'chandelier', 'cougar body', 'cougar face', 'crab', 'crayfish', 'crocodile', 'crocodile head', 'cup', 'dalmatian', 'dollar bill', 'dolphin', 'dragonfly', 'electric guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo head', 'garfield', 'gerenuk', 'gramophone', 'grand piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline skate', 'joshua tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea horse', 'snoopy', 'soccer ball', 'stapler', 'starfish', 'stegosaurus', 'stop sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water lilly', 'wheelchair', 'wild cat', 'windsor chair', 'wrench', 'yin yang']\n"
     ]
    }
   ],
   "source": [
    "data = io.loadmat(os.path.join(RAW_DATA_PATH, 'caltech101_silhouettes_28_split1.mat'))\n",
    "data.keys()\n",
    "\n",
    "X_train, y_train = data['train_data'], data['train_labels']\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_val, y_val = data['val_data'], data['val_labels']\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "X_test, y_test = data['test_data'], data['test_labels']\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "total = X_train.shape[0] + X_val.shape[0] + X_test.shape[0]\n",
    "print(\"Train: {:.2%}\".format(X_train.shape[0] / total), \n",
    "      \"Val: {:.2%}\".format(X_val.shape[0] / total), \n",
    "      \"Test: {:.2%}\".format(X_test.shape[0] / total))\n",
    "\n",
    "labels = list([x[0] for x in data['classnames'][0]])\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of each image: (784,)\n",
      "Range of values in the image: 0 - 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of each image:\", X_train[0].shape)\n",
    "print(\"Range of values in the image:\", X_train[0].min(), \"-\", X_train[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6936.8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size: (8671, 784) (8671, 1)\n",
      "Train: (6937, 784) (6937, 1)\n",
      "Val: (867, 784) (867, 1)\n",
      "Test: (867, 784) (867, 1)\n",
      "Total sum: 8671\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X_train, X_val, X_test))\n",
    "y = np.concatenate((y_train, y_val, y_test))\n",
    "\n",
    "N = X.shape[0]\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y,\n",
    "                                                        test_size=int(test_ratio * N),\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval,\n",
    "                                                    test_size=int(val_ratio * N),\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y_trainval)\n",
    "print(\"Original Size:\", X.shape, y.shape)\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "print(\"Total sum:\", X_train.shape[0] + X_val.shape[0] + X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partition(input_path, val_ratio, test_ratio, output_path):\n",
    "\n",
    "    data = io.loadmat(input_path)\n",
    "    X_train, y_train = data['train_data'], data['train_labels']\n",
    "\n",
    "    X_val, y_val = data['val_data'], data['val_labels']\n",
    "\n",
    "    X_test, y_test = data['test_data'], data['test_labels']\n",
    "\n",
    "    X = np.concatenate((X_train, X_val, X_test))\n",
    "    y = np.concatenate((y_train, y_val, y_test))\n",
    "\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y,\n",
    "                                                            test_size=int(test_ratio * N),\n",
    "                                                            random_state=42,\n",
    "                                                            stratify=y)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval,\n",
    "                                                        test_size=int(val_ratio * N),\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=y_trainval)\n",
    "    \n",
    "    assert X_train.shape[0] + X_val.shape[0] + X_test.shape[0] == total\n",
    "\n",
    "    # Create directories for train, val y test\n",
    "    train_path = os.path.join(output_path, 'train')\n",
    "    val_path = os.path.join(output_path, 'val')\n",
    "    test_path = os.path.join(output_path, 'test')\n",
    "\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(val_path, exist_ok=True)\n",
    "    os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "    # Save images\n",
    "    io.savemat(os.path.join(train_path, 'train_data.mat'), {'X': X_train, 'y': y_train})\n",
    "    io.savemat(os.path.join(val_path, 'val_data.mat'), {'X': X_val, 'y': y_val})\n",
    "    io.savemat(os.path.join(test_path, 'test_data.mat'), {'X': X_test, 'y': y_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = os.path.join(RAW_DATA_PATH, 'caltech101_silhouettes_28_split1.mat')\n",
    "output_path = f'input/data/train_{(1-val_ratio-test_ratio) * 100:.0f}_{val_ratio * 100:.0f}_{test_ratio * 100:.0f}'\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "create_partition(input_data, val_ratio, test_ratio, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
